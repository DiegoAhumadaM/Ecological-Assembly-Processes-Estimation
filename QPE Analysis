##---------------------------------------------------##
####    Ecological Assembly Processes Estimation   ####
##---------------------------------------------------##

# This script was developped by Guillaume Schwob and is based on the scripts developped by Stegen et al. 2013 (https://github.com/stegen/Stegen_etal_ISME_2013) and Richter-Heitmann et al. 2020 (https://github.com/FranzKrah/raup_crick)
# QPE Analysis

# Load packages
library(phyloseq)
library(metagMisc)
library(microbiome)
library(ape)
library(MicEco)
library(reshape2)
library(dplyr)


##### Functions to load ####

## This code is part of the study:
## Stochastic dispersal rather than deterministic selection explains the spatio-temporal distribution of soil bacteria in a temperate grassland
## doi: 10.3389/fmicb.2020.01391
## Franz-Sebastian Krah
## 02 - 27 - 2019

#' @title raup_crick_abu_par
#' @param com community matrix (spXsite)
#' @param reps number of bootstraps
#' @param ncore number of cores (serial: ncore = 1; parallel > 1)
#' @param classic_metric standardizes the metric to range from -1 to 1
#' @param split_ties adds half of the number of null observations that are equal to the observed number of shared species to the calculation- this is highly recommended
#' @details Parallelized version of the Raup-Crick algorithm for "abundance" data (Stegen et al. 2013).
#' Previous code loops over each pairwise community combination;
#' here we randomize the full community matrix and compute Bray-Curtis for the 
#' full matrix and then conduct subsequent Raup-Crick calculations as in Stegen.
#' This increaes computational speed. Further here implemented as multi-core version.
#' The code is acurate and fast (see paper, supplement section D)
#' @author Franz-Sebastian Krah
#' 


raup_crick_abu_par <- function(com, reps, ncore, classic_metric=FALSE, split_ties=TRUE){
  
  require("parallel")
  require("doSNOW")
  
  pb <- txtProgressBar(max =reps, style = 3)
  progress <- function(n) setTxtProgressBar(pb, n)
  opts <- list(progress = progress)
  cl <- makeCluster(ncore)
  registerDoSNOW(cl)
  
  bray.rand <- foreach(randomize = 1:reps, 
                       .options.snow = opts,
                       .packages = c("vegan", "picante")) %dopar% {
                         
                         
                         null.dist <- com*0
                         
                         for(i in 1:nrow(com)){
                           com.pa <- (com>0)*1
                           gamma<-ncol(com)
                           occur<-apply(com>0, MARGIN=2, FUN=sum)
                           abundance<-apply(com, MARGIN=2, FUN=sum)
                           com1 <- rep(0,gamma)
                           
                           com1[sample(1:gamma, sum(com.pa[i,]), replace=FALSE, prob=occur)]<-1
                           com1.samp.sp = sample(which(com1>0), (sum(com[i,])-sum(com1)),
                                                 replace=TRUE,prob=abundance[which(com1>0)]);
                           com1.samp.sp = cbind(com1.samp.sp,1)
                           com1.sp.counts = as.data.frame(tapply(com1.samp.sp[,2],com1.samp.sp[,1],FUN=sum))
                           colnames(com1.sp.counts) = 'counts'
                           com1.sp.counts$sp = as.numeric(rownames(com1.sp.counts))
                           com1[com1.sp.counts$sp] = com1[com1.sp.counts$sp] + com1.sp.counts$counts
                           x <- com1
                           null.dist[i,] <- x
                           rm('com1.samp.sp','com1.sp.counts')
                         }
                         as.matrix(vegdist(null.dist, "bray"))
                       }
  stopCluster(cl)
  
  ## Calculate beta-diversity for obs metacommunity
  bray.obs <- as.matrix(vegdist(com, "bray"))
  
  ##how many null observations is the observed value tied with?
  null_bray_curtis <- bray.rand
  num_exact_matching_in_null <- lapply(null_bray_curtis, function(x) x==bray.obs)
  num_exact_matching_in_null <- apply(simplify2array(num_exact_matching_in_null), 1:2, sum)
  
  ##how many null values are smaller than the observed *dissimilarity*?
  num_less_than_in_null <- lapply(null_bray_curtis, function(x) (x<bray.obs)*1)
  num_less_than_in_null <- apply(simplify2array(num_less_than_in_null), 1:2, sum)
  
  
  rc = (num_less_than_in_null)/reps; # rc;
  
  if(split_ties){
    
    rc = ((num_less_than_in_null +(num_exact_matching_in_null)/2)/reps)
  };
  
  
  if(!classic_metric){
    
    ##our modification of raup crick standardizes the metric to range from -1 to 1 instead of 0 to 1
    
    rc = (rc-.5)*2
  };
  
  return(rc)
  
}


### The entire script was made using the phyloseq objects of each compartment independently.
load("Fildes_wat.RData") #load phyloseq

wat.dat = phyloseq_to_df(Fildes_wat, addtax = F, addtot = F, addmaxrank = F, sorting = "abundance")
rownames(wat.dat) <- wat.dat[,1]#Assign OTU name to the rownames
wat.dat[,1] <- NULL#remove first column
wat.dat=as.data.frame(wat.dat)#transform data frame
wat.dat.t=t(wat.dat)#transpose data frame row=samples, columns=OTUs
meta.wat = microbiome::meta(Fildes_wat)#Metadata
b<-as.data.frame(meta.wat$Compartment)#vector with type of habitat
row.names(b) = meta.wat[,1]#assign samples names as rownames 
names(b)[names(b) == 'meta.wat$Compartment'] <- 'Compartment'
mer.wat<-merge(b, wat.dat.t, by=0, all=TRUE)#merge vector habitat with abundance data
row.names(mer.wat) = mer.wat$Row.names
com.wat <- mer.wat#community data
env.war <- com.wat[, 1:2] #information of samples
com.wat <- com.wat[, -c(1:2)] #remove 2 first columns
rowSums(com.wat>0) #total abundances per sample
com.wat <- com.wat[rowSums(com.wat>0) > 1, ] #keep samples with at least one abundances
colSums(com.wat>0) #total abundances per OTUs
com.wat <- com.wat[ , colSums(com.wat>0) >= 1, ] #keep OTUs with at least one abundances
dim(com.wat)
# 81 1409

## Phylogenetic beta turnover
# simulating a phylogenetic tree
tree.wat<- ape::read.tree("PhyML_Newick_tree.withoutConstrains.rooted")
tree.wat$tip.label
# get only the tree tips corresponding to the mer files colnames
pruned.phy.wat <- ape::drop.tip(tree.wat, tree.wat$tip.label[!tree.wat$tip.label %in% colnames(com)])#Subset the tree with the OTUs from sediment
pruned.phy.wat$tip.label
phy.dist.wat <- cophenetic(pruned.phy.wat)#extract cophenetic distances between OTUs : measure of the phylogenetic distance
rownames(phy.dist.wat) <- colnames(phy.dist.wat) <- colnames(com.wat) #To order row and columns of the distance matrix with the same order as OTU table
# Check the order of the distance matrices.
head(rownames(phy.dist.wat))
head(colnames(phy.dist.wat))
head(colnames(com.wat))

##### RUN once and save the outputs #####

# Run betaMNTD/=-betaNTI
nti_Fildes_wat <- MicEco::ses.comdistnt(com.wat, phy.dist.wat, null.model = "taxa.labels",
                                        runs = 999, iterations = 999, cores = 20)
saveRDS(nti_Fildes_wat,"nti_Fildes_wat.RDS")

# Raup-Crick
rc_Fildes_wat <- raup_crick_abu_par(com.wat, reps = 999, ncore = 14)
rc2 = data.frame(as.matrix(rc_Fildes_wat))
colnames(rc2)=colnames(rc_Fildes_wat$comdistnt.obs.z)

saveRDS(rc2,"rc_Fildes_wat.RDS")

##### Outputs processing #####

nti_Fildes_wat <- readRDS("~/nti_Fildes_wat.RDS")
rc_Fildes_wat <- readRDS("~/rc_Fildes_wat.RDS")

nti_wat <-nti_Fildes_wat$comdistnt.obs.z %>% melt() #Extract results and transform matrix, one value for each samples comparison
rc_wat <-rc_Fildes_wat%>% melt()  #Extract results and transform matrix, one value for each samples comparison

#Make a matrix with both results and ad column with the corresponding ecological process based on the BNTI and RC values
matrix_bnti_rc_wat <-nti_wat %>% mutate(RC=rc_wat$value) %>% rename(beta_NTI = value)

matrix_bnti_rc_wat$beta_NTI = as.numeric(matrix_bnti_rc_wat$beta_NTI) #transform to numeric
matrix_bnti_rc_wat$RC = as.numeric(matrix_bnti_rc_wat$RC) #transform to numeric

####### Processes  estimation #####

#function for the calculation of assembly processes 
evaluate_conditions <- function(data_frame) {
  num_rows <- nrow(data_frame)
  results <- vector("character", length = num_rows)
  
  for (i in 1:num_rows) {
    beta_NTI <- data_frame[i, "beta_NTI"]
    RC <- data_frame[i, "RC"]
    
    if (!is.na(beta_NTI) && !is.na(RC)) {
      if (beta_NTI < -2) {
        results[i] <- "Homogeneous selection"
      } else if (beta_NTI > 2) {
        results[i] <- "Variable selection"
      } else if (-2 <= beta_NTI && beta_NTI <= 2) {
        if (RC < -0.95) {
          results[i] <- "Homogenizing dispersal"
        } else if (RC > 0.95) {
          results[i] <- "Dispersal limitation"
        } else if (-0.95 <= RC && RC <= 0.95) {
          results[i] <- "Ecological drift"
        }
      }
    } else {
      results[i] <- "NA"
    }
  }
  
  return(results)
}

#calculation
result_labels <- evaluate_conditions(matrix_bnti_rc_wat) ####calculation
matrix_bnti_rc_wat$Process <- result_labels ### add results to new column 


####### Construction of annotated matrices + Quantification of the relative contribution of assembly processes #####

matrix_wat = na.omit(matrix_bnti_rc_wat)

matrix_wat$Dataset=NA
matrix_wat$Micro=NA

#Construction of each category 
matrix_wat_2 <- matrix_wat %>%
  mutate(Micro = ifelse(Compartment1 == "Water" & Compartment2 == "Water", "Water", Micro)) %>%
  mutate(Dataset = ifelse(Year1 == Year2 &
                            Ecosystem1 == Ecosystem2 &
                            Compartment1 == "Water" & Compartment2 == "Water", "Intra ecosystem", Dataset)) %>% 
  mutate(Dataset = ifelse(Year1 == Year2 &
                            Ecosystem1 != Ecosystem2 &
                            Compartment1 == "Water" & Compartment2 == "Water", "Inter ecosystem", Dataset)) %>% #spatial turnover
  mutate(Dataset = ifelse(Year1 != Year2 &
                            Ecosystem1 == Ecosystem2 &
                            Compartment1 == "Water" & Compartment2 == "Water", "Inter years", Dataset)) %>% #temporal turnover
  mutate(Dataset = ifelse(Year1 != Year2 &
                            Ecosystem1 != Ecosystem2 &
                            Compartment1 == "Water" & Compartment2 == "Water", "d.year_d.eco", Dataset)) %>% # all samples
  na.omit()
nrow(matrix_wat_2)
# 6480 rows

counts <- matrix_wat_2 %>%
  mutate(Conca = paste(Year1, Year2, Ecosystem1, Ecosystem2, sep = "_")) %>%
  dplyr::select(-Year1, -Year2, -Ecosystem1, -Ecosystem2) %>%
  dplyr::group_by(Micro, Dataset, Conca, Process) %>%
  dplyr::summarise(Count = dplyr::n(), .groups = "drop")

all_levels1 <- expand.grid(Conca=levels(factor(counts$Conca)),
                           Process = levels(factor(counts$Process)),
                           Micro= levels(factor(counts$Micro)),
                           Dataset=levels(factor(counts$Dataset)))
# Merge the counts with all possible levels and fill missing counts with 0
result_df1 <- all_levels1 %>%
  left_join(counts, by = c("Micro","Dataset","Conca","Process")) %>%
  mutate(Count = ifelse(is.na(Count), 0, Count))
# View(result_df)
sum(result_df1$Count)
# 6480 counts

# Transform in %
result_df3 <- result_df1 %>%
  dplyr::group_by(Micro, Dataset, Conca, Process) %>%
  dplyr::summarise(count.tot=sum(Count)) %>%
  dplyr::ungroup()

sum(result_df3$count.tot)
# 6480 rows
# View(result_df3)

# Calculate the percentage within each condition
result_df4 <- result_df3 %>%
  dplyr::group_by(Micro, Dataset, Conca) %>%
  mutate(percent = (count.tot / sum(count.tot)) * 100) %>%
  dplyr::ungroup() %>%
  na.omit()

sum(result_df4$count.tot) # 6480 counts
# View(result_df3)
# File ok !
result_df4_wat = result_df4
# Calculate the mean and the se
mean_result_df4 <- result_df4_wat %>%
  dplyr::group_by(Micro,Dataset, Process) %>%
  dplyr::summarise(mean_percent = mean(percent),
            se = sd(percent) / sqrt(n()))



##### Permutations calculate change in contribution####
#This permutation was related by comparing each category.

# Load the required library
library(exactRankTests)

# List of different compartment
microenv <- c("Sediment", "Water")

# List of different result values
processes <- c("Dispersal limitation", "Ecological drift", "Homogenizing dispersal", "Homogeneous selection", "Variable selection")

# Create an empty dataframe to store the results
result_summary_df <- data.frame(Microenvironment = character(0), Result = character(0), Mean_Difference = numeric(0), 
                                Lower_CI = numeric(0), Upper_CI = numeric(0), P_Value = numeric(0))

# Perform the analysis for each microenvironment and process 
#  data_combined4: datframe contains the calculated percentages of the assembly processes within each category for each compartment
for (micro in microenv) {
  result_df3_t <- data_combined4[data_combined4$Micro == micro, ]
  
  for (result_value in processes) {
    a <- result_df3_t[result_df3_t$Dataset == "d.year_s.eco" & result_df3_t$Process == result_value, ]
    b <- result_df3_t[result_df3_t$Dataset == "s.year_s.eco" & result_df3_t$Process == result_value, ]
    
    d.year_s.eco <- as.numeric(a$percent)
    s.year_s.eco <- as.numeric(b$percent)
    
    # Calculate mean difference consistently
    mean_difference <- mean(d.year_s.eco) - mean(s.year_s.eco)
    
    # Perform permutation test with confidence interval
    perm_test_result <- perm.test(d.year_s.eco, s.year_s.eco, alternative = "two.sided", method = "exact")
    
    # Calculate standard error
    se <- sqrt(var(d.year_s.eco)/length(d.year_s.eco) + var(s.year_s.eco)/length(s.year_s.eco))
    
    # Calculate margin of error
    margin_of_error <- abs(qnorm(0.975) * se)
    
    # Calculate 95% confidence interval
    lower_ci <- mean_difference - margin_of_error
    upper_ci <- mean_difference + margin_of_error
    
    # Create a new row for the result summary dataframe
    result_summary_row <- data.frame(Microenvironment = micro,
                                     Result = result_value,
                                     Mean_Difference = mean_difference,
                                     Lower_CI = lower_ci,
                                     Upper_CI = upper_ci,
                                     P_Value = perm_test_result$p.value)
    
    # Append the result summary row to the dataframe
    result_summary_df <- bind_rows(result_summary_df, result_summary_row)
  }
}

result_summary_df$effect = "Year-induced"
Year = result_summary_df
# Print the results
print(Year)

